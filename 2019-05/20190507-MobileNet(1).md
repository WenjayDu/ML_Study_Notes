# MobileNet

Authors propose a new class of efficient NN called MobileNets to train models for embedded applications like mobile phone. In this architecture, authors introduce 2 global hyper-parameters (width multiplier and resolution multiplier), which enables the model builder to choose the right size for model based on constraints of the problem, to efficiently obtain a balance between latency and accuracy. 

MobileNets are based on depth-wise separable convolutions which are core layers in MobileNet architecture, initially presented in paper<sup>[2]</sup>. Depth-wise separable convolutions is `a form of factorized convolutions, which factorize a standard convolution into a depth-wise convolution and a 1x1 convolution called a pointwise convolution`. 

What exactly depth-wise separable convolutions are? Well, a standard convolution finishes filtering and combining inputs into a new set of outputs in one step, while the depth-wise separable convolution splits this step into 2 layers, one separate layer for filtering called the depth-wise convolution and the other for combining called the pointwise convolution. And for MobileNets, the former applies a single filter to each input channel and the latter then applies a 1x1 convolution to combine the outputs of the former. And authors say, this factorization can help to dramatically reduce computation and model size. The result of calculation indicates that MobileNets use between 8 to 9 times less computation than networks using standard convolutions, at only a negligible loss in accuracy.


## References
1. Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam: *MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications*. In 2017.
2. L. Sifre. *Rigid-motion scattering for image classification.* PhD thesis, Ph. D. thesis, 2014.