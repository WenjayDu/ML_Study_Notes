# Dropout

NNs perform worse on test datasets than on training datasets mainly because hidden units are trained to work well together on training datasets rather than on test ones. This is overfitting. Authors have the view that preventing the `complex co-adaptations` can help reduce overfitting. 

What is `co-adaptation`? In conventional NNs, neurons are influenced by others due to connections between them. And if neurons have highly correlated behavior, this situation is referred as co-adaptation. Furthermore, it brings overfitting.

To prevent the co-adaptation, dropout is a notable regularization method, which makes hidden units randomly ignored from the NN with a probability of 0.5 during training, and of course, ignored units cannot participate in training. As a result, a hidden unit cannot rely on others being present. 

From another perspective, dropout can also be seen as an efficient ensemble learning method -- because of its randomness when choosing to make neurons ignored, dropout makes its training process equivalent to training a lot of different NNs. And during the testing phase, the result given by the model is an average of these NNs' output.

## References
1. Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan R Salakhut-dinov. Improving neural networks by preventing co-adaptation of feature detectors.